\documentclass[11pt,a4paper]{article}
\usepackage{a4wide}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{graphics,graphicx,epsfig}
\usepackage{amssymb,amsfonts,amsthm,amsmath,mathtext,cite,enumerate,float}
\usepackage[english,russian]{babel}
\usepackage[all]{xy}
\usepackage{morefloats}
\usepackage{pgf}
\usepackage[debug,outputdir={docgraphs/}]{dot2texi}
\usepackage{tikz}
\usepackage{scalefnt}
\usepackage{listings}
\usepackage{float}
\usepackage{verbatim}
\usepackage{placeins}
\usepackage{url}
\usepackage{babelbib}
\usepackage{pbox}
\usepackage{grffile}
\usepackage{color}
\usepackage{xfrac}
\usepackage{comment}
\usepackage{rotating}
\usepackage{cite}
\usepackage{sectsty}
\usepackage{caption}
\usepackage{subcaption}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{decorations.pathmorphing}

% Comment the following block when compiling this .tex with a saner compiler than texlive.
\makeatletter
\def\@settitle{\begin{center}%
    \baselineskip14\p@\relax
    \bfseries
    \@title
  \end{center}%
}

\renewcommand{\citedash}{]-[}
\renewcommand{\citepunct}{], [}

\renewcommand{\thesubfigure}{\asbuk{subfigure}}
\addto\captionsrussian{\renewcommand{\figurename}{Фиг.}}

\sectionfont{\centering\normalfont\small\MakeUppercase}

%\renewcommand{\section}{\@startsection {section}{1}%
%  \z@{.7\linespacing\@plus\linespacing}{.5\linespacing}%
%  {\normalfont}}
%\renewcommand{\section}{\@startsection {section}{1}
%  \z@{2.7ex \@plus 1ex}{1.0ex}%
%  {\normalfont}}
\makeatother

\theoremstyle{definition}
\newtheorem{algo}{Алгоритм}
\newtheorem{theorem}{Теорема}
\newtheorem{stat}{Утверждение}
\newtheorem{defin}{Определение}
\newtheorem{note}{Замечание}

\begin{document}

\begin{center}
  %ПОРОЖДЕНИЕ СУЩЕСТВЕННО НЕЛИНЕЙНЫХ РЕГРЕССИОННЫХ МОДЕЛЕЙ, УСТОЙЧИВЫХ К ПОГРЕШНОСТЯМ В ИЗМЕРЯЕМЫХ
  %ДАННЫХ
  ОПТИМИЗАЦИЯ ПАРАМЕТРОВ СУЩЕСТВЕННО НЕЛИНЕЙНЫХ РЕГРЕССИОННЫХ МОДЕЛЕЙ С УЧЕТОМ ПОГРЕШНОСТИ КАК ЗАВИСИМЫХ, ТАК И НЕЗАВИСИМЫХ ПЕРЕМЕННЫХ В ОБУЧАЮЩЕЙ ВЫБОРКЕ

  \bigskip
  Г.\,И.~Рудой
\end{center}

\begin{abstract}
  Для восстановления нелинейной зависимости показателя преломления среды от длины
  волны рассматривается набор индуктивно порожденных моделей с целью выбора оптимальной.
  Применяется алгоритм индуктивного порождения допустимых существенно
  нелинейных моделей и модифицированный алгоритм Левенберга-Марквардта. Предлагается
  критерий определения погрешности коэффициентов порожденных суперпозиций, называемый
  устойчивостью, а также метод оценки устойчивости полученного решения.
  Приводятся результаты численного моделирования на данных, полученных в ходе
  эксперимента по определению состава смеси по суммарной дисперсии.

  \bigskip
  \textbf{Ключевые слова}: \emph{символьная регрессия, нелинейные модели, индуктивное порождение,
	устойчивость решений, дисперсия прозрачной среды.}
\end{abstract}

\section*{Введение}

Для анализа результатов физического эксперимента, как правило, требуется
восстановить функциональную зависимость, описывающую соотношение измеряемых
величин. При этом необходимо, чтобы эксперт имел возможность интерпретировать
полученную зависимость, исходя из соответствующих теоретических моделей. Во
многих случаях вид функциональной зависимости заранее известен, либо необходимо
сделать выбор между несколькими (также заранее известными) вариантами моделей.

Одним из методов, позволяющих строить интерпретируемые модели, является
символьная регрессия\cite{davidson_2000_snrea,reference/ml/X10vc,StrijovW10,Strijov08InductMethods,Rudoy13},
порождающая, в том числе, и структурно сложные нелинейные модели. Различные
приближения сравниваются согласно ошибке на измеряемых данных, при этом оптимизация
параметров модели проводится, например, с помощью алгоритма Левенберга-Марквардта\cite{Marquardt1963Algorithm,more_78}.

Однако при анализе физического эксперимента важны не только значения самих
параметров искомой функциональной зависимости, но и погрешности их определения,
обусловленные погрешностями измеряемых в эксперименте величин. Для задачи
линейной регрессии соответствующая задача решена в частном случае, когда
погрешность определения регрессора пренебрежимо мала, а погрешность определения
зависимой переменной во всех экспериментальных точках одинакова\cite{Vatunin05}.
Для более сложного случая нелинейной регрессии и ситуации, когда необходимо
учитывать погрешности как регрессора, так и зависимой переменной (которые при
этом могут быть разными в различных экспериментальных точках), подобная задача,
насколько нам известно, не ставилась.

В настоящей работе метод нелинейной регрессии применяется для восстановления
зависимости показателя преломления $n$ от длины волны $\lambda$ в полосе
прозрачности полимера, включающей видимую и ближнюю инфракрасную области спектра.
Цель экспериментаторов состояла в том, чтобы по известной дисперсии для каждого
полимера с учетом того, что показатель преломления смеси химически инертных
полимеров равен взвешенной сумме (с соответствующими весами) показателей
преломления компонентов, определить состав смеси по экспериментально
определенной зависимости $n(\lambda)$. Другими словами, для случая двух
полимеров, заранее измерив и вычислив зависимости $n_1(\lambda)$ и $n_2(\lambda)$,
необходимо экспериментально определить суммарную зависимость
$n(\lambda) = \alpha n_1(\lambda) + (1 - \alpha) n_2(\lambda)$ и по ней
вычислить коэффициент $\alpha$, имеющий смысл концентрации первого полимера в
смеси.

Поскольку показатели преломления для прозрачных полимеров близкого химического
состава различаются незначительно, учет погрешности определения коэффициентов
функциональной зависимости $n(\lambda)$ и их связи с погрешностями
экспериментального определения длины волны $\lambda$ и показателя преломления
$n$ имеет принципиальное значение. Указанная связь важна еще и потому, что
именно она определяет требования к точности и чувствительности измерительной
аппаратуры и, следовательно, влияет на стоимость и продолжительность
эксперимента.

Обычно в рефрактометрах используются источники широкополосного (непрерывного)
спектра, а погрешность выделения конкретной длины волны определяется аппаратной
функцией используемого монохроматора (прибора, выделяющего узкий спектральный
диапазон) и подробно рассматривается, например, в\cite{Malishev79,Zaidel72}.
В большинстве случаев погрешность $\lambda$ может быть рассчитана, а также
определена экспериментально с использованием узкополосных источников света
(лазеров, известных атомных переходов вроде триплета ртути или дублета натрия,
и т.~д.). Характерная относительная погрешность определения длины волны в
рассматриваемой задаче обычно составляет $0.03 \div 0.5\%$, а 
абсолютная погрешность определения длины волны, как правило, меняется с
изменением самой длины волны. Экспериментальная погрешность показателя
преломления $n$ зависит от выбранного способа его измерения и, например,
при определении $n$ по углу полного внутреннего отражения обусловлена
непараллельностью используемых световых пучков, погрешностями в измерении углов
и т.~д, и составляет от $(1 \div 2) \cdot 10^{-5}$ для приборов высокого класса
точности до $(1 \div 10) \cdot 10^{-4}$. Для рассматриваемых в настоящей работе
задач существенно то, что величины погрешностей могут считаться известными и,
возможно, различными для каждой экспериментальной точки.

Стандартные методы нахождения оптимальных параметров существенно нелинейных
моделей (например, алгоритм Левенберга-Марквардта), основываются на предположении
о точно измеряемых величинах в обучающей выборке. Однако, в настоящей работе
данное предположение не рассматривается, поэтому использование подобных методов
представляется неточным.
Задача оценки параметров линейных функций рассматривается, например, в
\cite{Strutz11} для случая неточно измеренных зависимых переменных в линейной
регрессии. В частности, показывается, что для случая гетероскедастичности ошибок
при отсутствующей корреляции предложенный в \cite{Strutz11} метод вырождается во
взвешенную сумму квадратов, где веса обратно пропорциональны дисперсиям ошибок.
В связи с этим представляет интерес дальнейшая проработка методов оценки параметров
существенно нелинейных моделей при наличии ошибок в измерениях.

В настоящей работе на примере дисперсионной зависимости показателя преломления
исследуется возможность применения предложенного в \cite{Rudoy13} алгоритма
восстановления нелинейной регрессии. Результаты его работы сравниваются с
результатами применения SVM-регрессии.
Предложена модификация алгоритма Левенберга-Марквардта,
основывающаяся на предполжении об отсутствии автокорреляции ошибок,
а также о наличии ошибок измерения независимых переменных.
Кроме того, рассмотрено влияние штрафа
за сложность на качество и структурную сложность порождаемых суперпозиций.
Формально поставлена задача определения устойчивости регрессионной зависимости
от произвольного набора независимых переменных в общем виде, предложен метод
оценки устойчивости решения к погрешностям измерений, и изучена зависимость
этих характеристик от параметров модели для конкретного случая определения
дисперсии полимеров.

В первой части работы поставлена задача восстановления дисперсии полимера и
предложено понятие устойчивости суперпозиции, позволяющее учитывать и анализировать
зависимость погрешностей различных коэффициентов порожденной суперпозиции от
погрешности измеряемых данных.
Во второй части вкратце описывается алгоритм \cite{Rudoy13},
используемый для порождения аналитической функции-суперпозиции, аппроксимирующей
данные. В третьей части предложен численный метод нахождения устойчивости
суперпозиции. В четвертой части приводятся результаты вычислительного
эксперимента на реальных данных. Рассматривается два полимера в области прозрачности,
для каждого из которых имеется 17 экспериментальных точек,
соответствующих величине коэффициента преломления при различных значениях длины волны.

\section{Постановка задачи}

\paragraph{Задача регрессии.}
Дана выборка $D$ из $\ell$ результатов измерений коэффициента
преломления для некоторого полимера:
$D = \{ \lambda_i, n_i \mid i \in \{ 1, \dots, \ell \} \}$, где $\lambda_i$~--- длина волны,
а $n_i$~--- измеренный коэффициент преломления в $i$-ом измерении.

Требуется найти функцию $\hat{f} = \hat{f}(\lambda)$, минимизирующую стандартный
функционал потерь в предположении о нормальности случайной ошибки эксперимента:
\begin{equation}
  S(f, D) = \sum_{i = 1}^\ell (f(\lambda_i) - n_i)^2 \rightarrow \min_{f \in \mathcal{F}},
  \label{eq:s}
\end{equation}
где $D = \{ \lambda_i, n_i\}$, а $\mathcal{F}$~---
некоторое множество суперпозиций, из которого выбирается оптимальная.

Иными словами,
\begin{equation}
  \hat{f}(\lambda) = \hat{f}_D(\lambda) = \mathop{\arg \min}\limits_{f \in \mathcal{F}} S(f, D).
  \label{eq:fhat}
\end{equation}

\paragraph{Задача оценки устойчивости.}
Введем в общем виде понятие устойчивости суперпозиции $f$, характеризующей
поведение коэффициентов суперпозиции $\hat{f}$ при небольшом случайном
изменении исходной обучающей выборки
$D = \{ \mathbf{x}_i, y_i \}$,
где $\mathbf{x}_i$~--- исходное (полученное в ходе эксперимента)
признаковое описание $i$-го объекта, а $y_i$~--- соответствующее экспериментально
измеренное значение функции, которую требуется восстановить.

Функционал потерь \eqref{eq:s} в этом случае выглядит следующим образом: 
\begin{equation}
  S(f, D) = \sum_{i = 1}^\ell (f(\mathbf{x}_i) - y_i)^2 \rightarrow \min_{f \in \mathcal{F}}.
  \label{eq:s_common}
\end{equation}

Условимся также обозначать матрицу плана $X = \| x_{ij} \|$, строками которой
являются признаковые описания объектов выборки $D$. Иными словами, $x_{ij}$
обозначает $j$-ую компоненту признакового описания $i$-го объекта.

Рассмотрим вектор параметров
$\boldsymbol{\omega}_f = \{ \omega_i^f \mid i \in \{ 1, \dots, l_f \} \}$
некоторой суперпозиции $f$: $f(\mathbf{x}) = f(\mathbf{x}, \boldsymbol{\omega}_f)$.
Пусть для некоторой выборки $D = \{ \mathbf{x}_i, y_i \}$ и функции
$f$ вектор параметров $\hat{\boldsymbol{\omega}}_f(D)$ минимизирует
функционал \eqref{eq:s_common} с суперпозицией $f$, имеющей фиксированную
структуру:
\[
  \hat{\boldsymbol{\omega}}_f(D) = \mathop{\arg \min}\limits_{\boldsymbol{\omega}_f} S(f, D).
\]

Пусть также дана матрица стандартных отклонений
независимых переменных $\Sigma^{\mathbf{x}} = \| \sigma^{\mathbf{x}}_{ij} \|$,
где $\sigma^{\mathbf{x}}_{ij}$ характеризует стандартное отклонение $j$-ой
компоненты признакового описания $\mathbf{x}_i$ $i$-го объекта обучающей выборки,
и вектор стандартных отклонений $\boldsymbol{\sigma}^y$, где $\sigma^y_i$
характеризует стандартное отклонение зависимой переменной, соответствующей
$i$-му объекту.
Рассмотрим выборку $\acute{D}$, полученную из исходной выборки $D$
добавлением к каждой компоненте реализаций нормально распределенных
случайных величин с нулевым матожиданием и соответствующей
$\Sigma^{\mathbf{x}}$ и $\boldsymbol{\sigma}^y$ дисперсией:
\begin{equation}
  \acute{D}(\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}^y) = \{ \mathbf{x}_i + \boldsymbol{\xi}^{\mathbf{x}}_i, y_i + \xi^y_i \mid i \in 1, \dots, \ell; \boldsymbol{\xi}^{\mathbf{x}}_i \sim \mathcal{N}(0; \boldsymbol{\sigma}^{\mathbf{x}}_{i \cdot}); \xi^y_i \sim \mathcal{N}(0; \sigma^y_i) \}.
  \label{eq:d_acute}
\end{equation}

Для этой выборки $\acute{D}$ найдем оптимальный вектор $\hat{\boldsymbol{\omega}}_f (\acute{D} (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y))$
параметров суперпозиции $f$, минимизирующий функционал \eqref{eq:s}:
\begin{equation}
  \hat{\boldsymbol{\omega}}_f (\acute{D} (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y)) = \mathop{\arg \min}\limits_{\boldsymbol{\omega}_{f_D} \in R^{\mid \hat{\boldsymbol{\omega}}_f \mid}} S (f_D (\cdot, \boldsymbol{\omega}_{f_D}), \acute{D} (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y)).
  \label{eq:hat_omega}
\end{equation}
Понятно, что $\hat{\boldsymbol{\omega}}_f (\acute{D} (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y))$~---
векторная случайная величина, и, следовательно,
\[
  \Delta\hat{\boldsymbol{\omega}}_f(\acute{D} (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y) ) = \hat{\boldsymbol{\omega}}_f(D) - \hat{\boldsymbol{\omega}}_f (\acute{D} (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y))
\]
также векторная случайная величина.

Пусть дано множество $\acute{\mathcal{D}}_N$ из $N$ таких выборок, где каждая выборка
соответствует отдельным реализациям случайных величин из \eqref{eq:d_acute}:
\[
  \acute{\mathcal{D}}_N (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y) = \{ \acute{D}_1 (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y), \dots, \acute{D}_N (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y) \},
\]
и пусть $\overline{\sigma}_i$~--- эмпирическое стандартное отклонение $i$-ой компоненты
векторной случайной величины
$\Delta\hat{\boldsymbol{\omega}}_f(\acute{D} (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y) )$
на множестве $\acute{\mathcal{D}}_N (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y)$.
\begin{defin}
\emph{Относительной устойчивостью} (или просто \emph{устойчивостью}) параметра
$\omega_i$ относительно $j$-ой компоненты векторного описания при исходной
обучающей выборке $D$ и параметрах $\acute{\mathcal{D}}_N (\Sigma^{\mathbf{x}}, \boldsymbol{\sigma}_y)$
будем называть следующую величину:
\begin{equation}
  T_{ij}(f) =
	\begin{cases}
	  \displaystyle \frac{\frac{\overline{\sigma}_i}{\hat{\omega}_i}}{r\big(\{ \frac{\sigma_{kj}^{\mathbf{x}}}{x_{kj}} \}_{k \in \{ 1, \dots, \ell \}}\big)} & j \leq |\mathbf{x}| \\
	  \displaystyle \frac{\frac{\overline{\sigma}_i}{\hat{\omega}_i}}{r\big(\{ \frac{\sigma_{k}^{y}}{y_k} \}_{k \in \{ 1, \dots, \ell \}}\big)} & j = |\mathbf{x}| + 1
	\end{cases}
  \label{eq:t_rel}
\end{equation}
где $r$~--- некоторая функция, переводящая вектор, составленный из соответствующих
дробей, в единственный скаляр.
\end{defin}

Функция $r$ позволяет сопоставить, вообще говоря, различным отношениям стандартного
отклонения зависимой переменной $y_i$ $i$-го объекта обучающей выборки и самого значения $y_i$
единственное число (аналогично и для $x_i$-й независимой переменной и ее стандартного отклонения).
Примерами такой функции могут являться среднее арифметическое
всех отношений или максимальное значение отношения, а конкретная функция выбирается
экспертом в зависимости от физического смысла задачи.
В настоящей работе предлагается выбирать значения стандартных отклонений так, чтобы
все значения соответствующих переменных были равны, поэтому функция $r$ может выбирать
любой из своих аргументов.

Величина $T_{ij}(f)$ показывает, как относится стандартное отклонение
параметра $\hat{\omega}_i$, нормированное на значение этого параметра, к характерному стандартному
отклонению $j$-го элемента признакового описания, нормированного на значение этого
элемента. Например, если это отношение больше единицы, то погрешности определения коэффициента
$\hat{\omega}_i$ растут быстрее погрешностей измерения параметра.

В частности, в искомой задаче восстановления дисперсионной зависимости с учетом неизменной
относительной ошибки эксперимента:
\[
  T_{i0}(f) = \frac{\frac{\overline{\sigma}_i}{\hat{\omega}_i}}{\frac{\sigma_n}{n}},
\]
\[
  T_{i1}(f) = \frac{\frac{\overline{\sigma}_i}{\hat{\omega}_i}}{\frac{\sigma_{\lambda}}{\lambda}}.
\]

Требуется исследовать зависимость устойчивости $\mathbb{T}_{\hat{f}}$ относительно
$\sigma_n$ и $\sigma_{\lambda}$.

Отметим, что для простых случаев одномерной регрессии (каковым является исследование
дисперсионной зависимости полимеров), возможно, более наглядным является исследование
\emph{абсолютной стабильности}~--- зависимости величины
$\frac{\overline{\sigma}_i}{\hat{\omega}_i}$ от нормализованных вариаций в обучающей
выборке, $\frac{\sigma_n}{n}$ и $\frac{\sigma_{\lambda}}{\lambda}$ соответственно.
В этом случае возможно проиллюстрировать искомую зависимость интерпретируемым графиком.

\section{Метод оптимизации параметров существенно нелинейных суперпозиций}

Требуется минимизировать функционал \eqref{eq:s} в предположении об измерении
как зависимых, так и независимых переменных с погрешностями. Кроме того,
учитываются следующие требования:
\begin{itemize}
  \item При определении минимального расстояния от каждой точки обучающей
	выборки до регрессионной кривой учитывается наличие погрешностей как
	зависимых, так и независимых переменных.
  \item Метод оптимизации функционала является развитием имеющихся хорошо
	развитых итеративных методов оптимизации, вроде алгоритма
	Левенберга-Марквардта.
\end{itemize} 

Рассматривается случай зависимости $y = f(x, \boldsymbol{\omega})$, где
$x$~--- скалярная переменная, $\boldsymbol{\omega}$~--- вектор параметров
модели $f$.

Пусть стандартное отклонение измерения $y_i$~--- $\sigma_{y_i}$,
стандартное отклонение измерения $x_i$~--- $\sigma_{x_i}$.

Определим расстояние от точки $(x_i, y_i)$ до кривой
$y = f(x, \boldsymbol{\omega})$ следующим образом:
\[
  \rho^2(x_i, y_i, f | \boldsymbol{\omega}) =
	\mathop{\arg \min}\limits_x \Big(\frac{x_i - x}{\sigma_{x_i}}\Big)^2 +
	  \Big(\frac{y_i - f(x, \boldsymbol{\omega})}{\sigma_{y_i}}\Big)^2.
\]
К такому определению приводят следующие экспертные соображения:
\begin{itemize}
  \item Члены суммы, имеющие большее стандартное отклонение, должны иметь
	меньший вес при оптимизации. Иными словами, к неточно определенным данным
	подстраиваться необходимо не настолько строго, как к более точным.
  \item Числители имеют ту же размерность, что и соответствующие знаменатели,
	поэтому получается сумма двух безразмерных чисел, что корректно с точки
	зрения анализа размерностей.
\end{itemize}

Линеаризуем $f$ в окрестности $x_i$:
\[
  f(x, \boldsymbol{\omega}) = f(x_i, \boldsymbol{\omega}) + \frac{\partial f}{\partial x}(x_i, \boldsymbol{\omega})(x - x_i) + \text{o}(x - x_i).
\]
Получаем следующее выражение для расстояния:
\[
  \rho^2(x_i, y_i, f | \boldsymbol{\omega}) =
	\arg \min_x \Big(\frac{x_i - x}{\sigma_{x_i}}\Big)^2 +
	  \Big(\frac{y_i - f(x_i, \boldsymbol{\omega}) - \frac{\partial f}{\partial x}(x_i, \boldsymbol{\omega})(x - x_i)}{\sigma_{y_i}}\Big)^2.
\]
Минимизируя, получим выражение для минимального расстояния:
\[
  \rho^2(x_i, y_i, f | \boldsymbol{\omega}) = \frac{(y_i - f(x_i, \boldsymbol{\omega}))^2}{\sigma_{y_i}^2 + (\frac{\partial f}{\partial x}(x_i, \boldsymbol{\omega}))^2 \sigma_{x_i}^2}.
\]
Отметим, что числитель в этом выражении равен соответствующему $i$-ой точке
члену в функционале \eqref{eq:s}.

Таким образом, получаем следующий функционал, который необходимо минимизировать:
\begin{equation}
  \dot{S}(f, D) = \sum_{i = 1}^{\ell} \frac{(y_i - f(x_i, \boldsymbol{\omega}))^2}{\sigma_{y_i}^2 + (\frac{\partial f}{\partial x}(x_i, \boldsymbol{\omega}))^2 \sigma_{x_i}^2}.
  \label{eq:s_f_fixed}
\end{equation}

Для решения задачи
\[
  \hat{\omega} = \mathop{\arg \min}\limits_{\boldsymbol{\omega}} \sum_{i = 1}^{\ell} \frac{(y_i - f(x_i, \boldsymbol{\omega}))^2}{\sigma_{y_i}^2 + (\frac{\partial f}{\partial x}(x_i, \boldsymbol{\omega}))^2 \sigma_{x_i}^2}
\]
предлагается следующая итеративная процедура:
\begin{enumerate}
  \item Для каждой точки $(x_i, y_i)$ в обучающей выборке оптимизируемая
	функция $f(x, \boldsymbol{\omega})$ линеаризуется в окрестности этой
	точки. Иными словами, рассматривается частная производная
	$\frac{\partial f}{\partial x} = \frac{\partial f}{\partial x}(x, \boldsymbol{\omega})$.
  \item Каждый $i$-й член функционала \eqref{eq:s} нормируется на
	соответствующую величину
	\[
	  \sigma_{y_i}^2 + (\frac{\partial f}{\partial x}(x_i, \boldsymbol{\omega}))^2 \sigma_{x_i}^2,
	\]
	зависящую, в том числе, от текущего значения вектора параметров
	$\boldsymbol{\omega}$. Таким образом, получается новый функционал
	$\dot{S}(\boldsymbol{\omega})$.
  \item Выполняется одна итерация стандартного алгоритма, оптимизирующая
	функционал $\dot{S}$, в результате получается новое приближение вектора
	параметров $\boldsymbol{\omega}$.
  \item Шаги 1-3 выполняются до тех пор, пока не будет выполняться
	какое-либо условие останова (например, по числу итераций или по норме
	изменения вектора $\boldsymbol{\omega}$).
\end{enumerate}

Подробное обоснование таких свойств предложенной процедуры, как сходимость,
корректность и статистическая оптимальность не является предметом настоящей
работы.

Отметим, что на шаге 3 предложенной процедуры при достаточной гладкости
частной производной $\frac{\partial f}{\partial x} = \frac{\partial f}{\partial x}(x, \boldsymbol{\omega})$
представляется возможным выполнять сразу несколько итераций исходного
немодифицированного алгоритма Левенберга-Марквардта без пересчёта параметров
на шаге 1.

Кроме того, предложенный алгоритм естественным образом обобщается на случай
функций $f$ многих переменных.

\section{Метод исследования стабильности решения}

Для оценки устойчивости $\mathbb{T}_{\hat{f}}$ решения $\hat{f}$ задачи
\eqref{eq:s}, как предложено выше, фиксируется структурный вид суперпозиции
$\hat{f}$ и исследуется зависимость стандартного отклонения ее коэффициентов
как функция стандартного отклонения нормально распределенной случайной добавки
в исходных данных.

Иными словами, выбираются значения $\sigma_{\lambda}$ и $\sigma_n$, затем для этих
значений генерируется выборка $\acute{D}(\sigma_n, \sigma_{\lambda})$ согласно
\eqref{eq:d_acute}. Для этой выборки вычисляются значения коэффициентов суперпозиции
$\hat{f}$, минимизирующие функционал \eqref{eq:s} согласно \eqref{eq:hat_omega},
методом Левенберга-Марквардта.

Данная процедура для фиксированной пары $\sigma_{\lambda}$ и $\sigma_n$ повторяется
до достижения некоторого критерия останова (например, по количеству итераций),
после которого и рассчитывается $\mathbb{T}_{\hat{f}}$.

Повторяя описанные выше шаги для различных $\sigma_{\lambda}$ и $\sigma_n$, можно
оценить зависимость стандартного отклонения коэффициентов суперпозиции от
стандартного отклонения шума.

Из физических соображений ясно, что гладкая зависимость означает устойчивое в
физическом смысле решение, тогда как отклонения от гладкости означают
ту или иную ошибку в суперпозиции и могут являться свидетельством переобучения:
чем меньше коэффициенты зависят от случайных шумов в данных, тем больше обобщающая
способность.

Кроме того, сравнение различных суперпозиций может также производиться по
критерию устойчивости в дополнение к сравнению по сложности и по значению
функционала \eqref{eq:s}. В ряде практических приложений критерий устойчивости
может иметь приоритетное значение.

\section{Вычислительный эксперимент}

В вычислительном эксперименте используются данные, полученные в ходе
изучения возможности определения состава смеси прозрачных
полимеров по суммарной дисперсионной зависимости, если известна экспериментальная
зависимость дисперсии для каждого конкретного полимера. Рассматривается два
полимера, для каждого из которых имеется 17 экспериментальных точек,
соответствующих коэффициенту преломления при разных значениях длины волны.
Значения приведены в таблице \ref{tabl:source_data}.

\begin{table}[h]
  \footnotesize
  \caption{Экспериментальные значения коэффициентов преломления.}
  \centering
  \begin{tabular}{r | r | r}
	$\lambda$, нм	& Полимер 1 & Полимер 2 \\ \hline
	435.8 & 1.36852 & 1.35715 \\
	447.1 & 1.36745 & 1.35625 \\
	471.3 & 1.36543 & 1.35449 \\
	486.1 & 1.36446 & 1.35349 \\
	501.6 & 1.36347 & 1.35275 \\
	546.1 & 1.36126 & 1.35083 \\
	577.0 & 1.3599 & 1.34968 \\
	587.6 & 1.3597 & 1.34946 \\
	589.3 & 1.35952 & 1.34938 \\
	656.3 & 1.35767 & 1.34768 \\
	667.8 & 1.35743 & 1.34740 \\
	706.5 & 1.35652 & 1.34664 \\
	750 & 1.35587 & 1.34607 \\
	800 & 1.35504 & 1.34544 \\
	850 & 1.3544 & 1.34487 \\
	900 & 1.35403 & 1.34437 \\
	950 & 1.35364 & 1.34407 \\
  \end{tabular}
  \label{tabl:source_data}
\end{table}

Для получения суперпозиций используется алгоритм, предложенный в \cite{Rudoy13} и
решающий следующую задачу:
\begin{equation}
  Q_f = \frac{1}{1 + S(f)} \left(\alpha + \frac{1 - \alpha}{1 + \text{exp} (C_f - \tau)}\right) \rightarrow \min_{f \in \mathcal{F}},
  \label{eq:s_f_min}
\end{equation}
где:
\begin{itemize}
  \item[] $S(f)$~--- значение функционала потерь \eqref{eq:s} на данной выборке $D$;
  \item[] $C_f$~--- сложность суперпозиции, соответствующая количеству элементарных
	функций, свободных переменных и констант;
  \item[] $\alpha$~--- $0 \ll \alpha < 1$, характеризует влияние штрафа за сложность
	на качество суперпозиции (большие значения $\alpha$ отдают предпочтение более
	точным моделям, а меньшие~--- более простым);
  \item[] $\tau$~--- коэффициент, характеризующий желаемую сложность модели.
\end{itemize}

Предполагается, что дисперсионные свойства полимеров описываются одной и той
же функциональной зависимостью, так как подчиняются одним и тем же физическим
закономерностям. Поэтому сначала получена суперпозиция $\hat{f}$,
минимизирующая \eqref{eq:s_f_min} для первого полимера, а затем для каждого
из полимеров находятся соответствующие векторы параметров
$\hat{\boldsymbol{\omega}}_{\hat{f}}$ и оценивается устойчивость полученного решения.

Разделение на обучающую и контрольную выборку не производилось, однако переобучения
удается избежать и без такого разделения, опираясь целиком на штраф за сложность.

Из физических соображений следует \cite{Serova11}, что зависимость коэффициента
преломления $n$ от длины волны $\lambda$ должна выражаться суммой
четных степеней длины волны, поэтому множество элементарных функций состоит из
стандартных операций сложения и умножения:
\[
  g_1(x_1, x_2) = x_1 + x_2,
\]
\[
  g_2(x_1, x_2) = x_1 x_2,
\]
а также из функции
\[
  g_3(\lambda, p) = \frac{1}{\lambda^{2p}}.
\]

В ходе вычислительного эксперимента константы, меньшие $10^{-7}$,
заменялись на $0$.

В результате применения описанного выше алгоритма со значениями
$\alpha = 0.05$, $\tau = 10$ получена следующая суперпозиция
(константы округлены до пятой значащей цифры):
\begin{equation}
  f(\lambda) = 1.3495 + \frac{3.5465 \cdot 10^3}{\lambda^2} + \frac{2.023 \cdot 10^3}{\lambda^4},
  \label{eq:res_0}
\end{equation}
со сложностью $13$, среднеквадратичной ошибкой $2.4 \cdot 10^{-8}$ и значением $Q_f \approx 0.095$.
Длины волн выражаются в нанометрах.

Отметим, что обычно в приложениях учитывают только квадратичный член, а более
высокими степенями пренебрегают. Величина поправки, вносимой в результирующее значение
суперпозиции последним слагаемым, указывает на полное согласие полученных результатов
с принятой практикой.

\paragraph{Влияние штрафа за сложность.}

Исследуем, как влияет добавление нечетных степеней на результат решения задачи \eqref{eq:s_f_min},
заменив функцию $g_3$ в порождающем наборе на
\[
  g_3(\lambda, p) = \frac{1}{\lambda^p}.
\]

Следует отметить, что при тех же $\alpha = 0.05$ и $\tau = 10$ результирующей функцией остается
\eqref{eq:res_0}.

Увеличим $\tau$ до 30. Получим следующую формулу (константы округлены до третьей значащей цифры):
\begin{equation}
  n(\lambda) = 1.34 + \frac{11.6}{\lambda} + \frac{17.37}{\lambda^2} + \frac{0.0866}{\lambda^3} + \frac{2.95 \cdot 10^{-4}}{\lambda^4} + \frac{8.54 \cdot 10^{-7}}{\lambda^5},
  \label{eq:res_incorrect}
\end{equation}
сложность которой составляет $31$, и для которой среднеквадратичная ошибка
на выборке составляет $\approx 3.9 \cdot 10^{-9}$,
а значение $Q_f \approx 0.31$.

Иными словами, при большей желаемой сложности,
регулируемой параметром $\tau$, выигрывает более сложная (а в данном случае и
физически некорректная) модель, которая лучше описывает экспериментальные данные.

Как и следовало ожидать, чрезмерное увеличение $\tau$ ведет к переобучению.

\paragraph{SVM.}

В качестве базового алгоритма используется SVM-регрессия с RBF-ядром \cite{Vapnik79}.
Параметр $\gamma$ ядра подбирался по методу скользящего контроля, наилучшим результатом является
комбинация из $15$ опорных векторов c $\gamma \approx 2 \cdot 10^{-6}$, при этом
среднеквадратичная ошибка при кросс-валидации с тестовой выборкой, содержащей по 2
объекта, составляет $8.96 \cdot 10^{-8}$. Однако, проинтерпретировать полученную
решающую функцию не представляется возможным.

\paragraph{Исследование стабильности решения.}

Для оценки стабильности решения фиксировалась формула \eqref{eq:res_0} в виде
\[
  f(\lambda) = \omega_1 + \frac{\omega_2}{\lambda^2} + \frac{\omega_3}{\lambda^4},
\]
и исследовалась зависимость стандартного отклонения ее коэффициентов $\omega_1$,
$\omega_2$ и $\omega_3$ от стандартного отклонения
нормально распределенного случайного шума в исходных данных описанным выше методом.
Критерием останова в нем являлось достижение 10000 итераций для каждой пары
$(\sigma_{\lambda}, \sigma_n)$.

В таблице \ref{tabl:res_even} представлены
поверхности уровня дисперсии для первого, второго и третьего коэффициентов каждого из полимеров
соответственно.

\begin{table}[h]
  \centering
  \footnotesize
  \caption{Поверхности дисперсии для формулы \eqref{eq:res_0}.}
  \begin{tabular}{l | c c c}
	  & $\omega_1$ & $\omega_2$ & $\omega_3$ \\ \hline
	\begin{rotate}{90}Полимер 1\end{rotate} &	\includegraphics[scale=0.4]{figs/even/p1.txt_coeff0.dat.eps} & \includegraphics[scale=0.4]{figs/even/p1.txt_coeff1.dat.eps} & \includegraphics[scale=0.4]{figs/even/p1.txt_coeff2.dat.eps} \\
	\begin{rotate}{90}Полимер 2\end{rotate} &	\includegraphics[scale=0.4]{figs/even/p2.txt_coeff0.dat.eps} & \includegraphics[scale=0.4]{figs/even/p2.txt_coeff1.dat.eps} & \includegraphics[scale=0.4]{figs/even/p2.txt_coeff2.dat.eps}
  \end{tabular}
  \label{tabl:res_even}
\end{table}

\begin{table}[h]
  \centering
  \footnotesize
  \caption{Значения коэффициентов для формулы \eqref{eq:res_0} и их относительная разность.}
  \begin{tabular}{l | c | c | c | c}
				& $\omega_1$				& $\omega_2$				& $\omega_3$				& MSE	\\ \hline
    Полимер 1	& 1.34946				& 3558.95				& 1924.33				& $2.2 \cdot 10^{-8}$		\\
    Полимер 2	& 1.34047				& 3118.84				& 1578.59				& $1.4 \cdot 10^{-8}$		\\
	Разность		& $6.71 \cdot 10^{-3}$	& $1.41 \cdot 10^{-1}$	& $2.2 \cdot 10^{-1}$	&	\\
  \end{tabular}
  \label{tabl:res_even_coeffs}
\end{table}

\begin{table}[h]
  \centering
  \footnotesize
  \caption{Значения стандартного отклонения для коэффициентов формулы \eqref{eq:res_0} для первого полимера в зависимости от относительных дисперсий.}
  \begin{tabular}{l | c | c | c}
	$\omega_i$	& $\frac{\sigma_{\lambda}}{\lambda} = 2 \cdot 10^{-4}; \frac{\sigma_n}{n} = 2 \cdot 10^{-5}$	& $ \frac{\sigma_{\lambda}}{\lambda} = 6 \cdot 10^{-4}; \frac{\sigma_n}{n} = 6 \cdot 10^{-5} $	& $ \frac{\sigma_{\lambda}}{\lambda} = 9 \cdot 10^{-4}; \frac{\sigma_n}{n} = 2 \cdot 10^{-4} $ \\ \hline
	1		& $1.22 \cdot 10^{-5}$																			& $ 3.59 \cdot 10^{-5} $																		& $ 1.19 \cdot 10^{-4} $		\\
	2		& $1.48 \cdot 10^{-3}$																			& $ 4.38 \cdot 10^{-3} $																		& $ 1.44 \cdot 10^{-2} $		\\
  \end{tabular}
  \label{tabl:res_even_stddev}
\end{table}

Из графиков видно, что от шума, накладываемого на значения длины волны, дисперсия значений
первого и второго коэффициентов практически не зависит в достаточно широком диапазоне точности
определения длины волны, представляющем практический интерес. В то же время дисперсия значений
первого коэффициента зависит от дисперсии шума коэффициента преломления практически линейно,
тогда как для второго коэффициента после некоторого характерного значения зависимость становится слабой.

Физическая интерпретация этих результатов~--- при построении прибора для измерения дисперсии
такого типа полимеров в их полосе прозрачности значительное внимание следует уделять точности измерения коэффициента преломления,
тогда как измерения длины волны могут быть неточны вплоть до нескольких нанометров. Кроме того,
предложенный метод прямо указывает, на каких интервалах шума каким будет выигрыш в точности
определения параметров регрессионной модели в зависимости от увеличения точности измерений.

Принципиально важно, что значения стандартного отклонения параметров регрессионной
модели существенно меньше разности между самими значениями этих параметров по порядку величины
(см. таблицы \ref{tabl:res_even_coeffs} и \ref{tabl:res_even_stddev}), что означает, в частности,
что полимеры могут быть различены даже не очень точным рефрактометром.

\paragraph{Стабильность некорректного решения.}

Аналогично исследуем стабильность решения \eqref{eq:res_incorrect}. Приведем только графики
зависимости первых трех коэффициентов, см. таблицу \ref{tabl:res_incorrect}.

\begin{table}[h]
  \centering
  \footnotesize
  \caption{Поверхности дисперсии для формулы \eqref{eq:res_incorrect}.}
  \begin{tabular}{l | c c c}
	  & $\omega_1$ & $\omega_2$ & $\omega_3$ \\ \hline
	\begin{rotate}{90}Полимер 1\end{rotate} &	\includegraphics[scale=0.4]{figs/all/p1.txt_coeff0.dat.eps} & \includegraphics[scale=0.4]{figs/all/p1.txt_coeff1.dat.eps} & \includegraphics[scale=0.4]{figs/all/p1.txt_coeff2.dat.eps} \\
	\begin{rotate}{90}Полимер 2\end{rotate} &	\includegraphics[scale=0.4]{figs/all/p2.txt_coeff0.dat.eps} & \includegraphics[scale=0.4]{figs/all/p2.txt_coeff1.dat.eps} & \includegraphics[scale=0.4]{figs/all/p2.txt_coeff2.dat.eps}
  \end{tabular}
  \label{tabl:res_incorrect}
\end{table}

Из графиков видно, что в случае формулы \eqref{eq:res_incorrect} дисперсия соответствующих
параметров существенно превышает таковую для \eqref{eq:res_0}. В частности, второй, третий
и четвертый коэффициенты имеют дисперсию, на порядки превышающую характерные значения самих
коэффициентов.

Данные результаты свидетельствуют о переобучении, и что полученная модель не может быть
использована для надежного приближения экспериментальных данных ввиду большой чувствительности
к шумам.

\paragraph{Использование модифицированного алгоритма Левенберга-Марквардта.}

Сравним предложенный модифицированный алгоритм Левенберга-Марквардта,
предложенный в настоящей работе, с немодифицированным. Для этого выполним
оптимизацию параметров порождённой модели \eqref{eq:res_0} на исходных данных
для первого полимера. Получившиеся результаты в сравнении с результатами для
немодифицированного алгоритма приведены в таблице \ref{tabl:res_s_fixed}.

\begin{table}[h]
  \centering
  \caption{Значения коэффициентов для формулы \eqref{eq:res_0}, полученные согласно различным алгоритмам оптимизации.}
  \begin{tabular}{l | c | c | c}
							& $\omega_1$				& $\omega_2$				& $\omega_3$	\\ \hline
    АЛМ						& 1.34946				& 3558.95				& 1924.33				\\
    Модифицированный АЛМ	& 1.34948				& 3551.97				& 0.0230				\\
	Относительная разность	& $1.48 \cdot 10^{-5}$	& $1.963 \cdot 10^{-3}$	& $0.9999880$	\\
  \end{tabular}
  \label{tabl:res_s_fixed}
\end{table}

Отметим, что полученные результаты для модифицированного алгоритма отличаются от
стандартных незначительно (кроме третьего коэффициента), что объясняется достаточно медленно убывающей
регрессионной моделью. Соответственно, расстояние в направлении перпендикуляра
к линеаризованной прямой отличается от расстояния по вертикали незначительно.
Кроме того, в данной задаче погрешность измерения независимой переменной (длины
волны) достаточно мала, а погрешность измерения зависимой переменной (коэффициента
преломления) практически одинакова для всех точек в обучающей выборке, поэтому
нормирование на соответствующую величину приводит к практически равному уменьшению
каждого из членов функционала $\eqref{eq:s}$ и не имеет существенного виляния.
Однако, регрессионные модели другого вида демонстрируют более существенные различия.

Значительное отличие третьего коэффициента $\omega_3$ объясняется несущественным
вкладом соответствующего члена в сумму ввиду высокой степени при $\lambda$ в
знаменателе. Как следствие, он носит скорее случайный характер.

\section{Заключение}

Предложенный в \cite{Rudoy13} алгоритм позволяет получить интерпретируемую аналитическую
формулу, описывающую зависимость коэффициента преломления среды от длины волны.
Введенный штраф за сложность позволяет избежать переобучения без использования методов
вроде скользящего контроля, и, таким образом, отпадает необходимость в контрольной выборке.

Хотя другие алгоритмы, такие как SVM-регрессия, могут демонстрировать более высокое
качество приближения данных, их результаты неинтерпретируемы и не защищены от переобучения
<<по построению>>, поэтому требуют разделения выборки на обучающую и контрольную. Кроме
того, их структурные параметры так же требуют оценки по методам вроде кросс-валидации.

Предложенный в настоящей работе метод оценки стабильности решения позволяет исследовать вклад различных
членов результирующей суперпозиции и зависимость изменения этих членов от
случайных шумов во входных данных. В частности, в прикладных областях данный метод позволяет
выявить, какие именно элементы признакового описания объектов в генеральной совокупности
наиболее чувствительны к шуму. Кроме того, для корректных с экспертной точки зрения
решений оказывается, что они стабильны, в то время как некорректные результаты нестабильны.

\FloatBarrier

\bibliographystyle{babunsrt-lf}
%\bibliographystyle{babunsrt}
%\bibliographystyle{unsrt}
\bibliography{bibliography}

\end{document}
